{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DL-xS3wo1LtM",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Importanto bibliotecas e Definindo diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MINx5gXN1Pfc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "data_dir = f\"./data\"\n",
    "#corel-1k\n",
    "dataset_dir = f\"{data_dir}/dataset\"\n",
    "images_dir = f\"{dataset_dir}/images\"\n",
    "#caltech256\n",
    "dataset_1_dir = f\"{data_dir}/dataset_1\"\n",
    "images_1_dir = f\"{dataset_1_dir}/images\"\n",
    "#cifar100\n",
    "dataset_2_dir = f\"{data_dir}/dataset_2\"\n",
    "images_2_dir = f\"{dataset_2_dir}/images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Funções p/ escala de cinza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração de histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_vizinhos(matriz_de_intensidade, linha, coluna):\n",
    "    # O objetivo dessa função é retornar uma lista contendo a intensidade dos 9 vizinhos do pixel observado\n",
    "\n",
    "    #Esse método de partição da matriz foi escolhido para manter a analise dos pixels vizinhos\n",
    "    #dentro dos limites da matriz de intensidade, evitando assim valores negativos ou fora do shape.\n",
    "    vizinhos = matriz_de_intensidade[max(0, linha-1):min(matriz_de_intensidade.shape[0], linha+2),\n",
    "                             max(0, coluna-1):min(matriz_de_intensidade.shape[1], coluna+2)]\n",
    "\n",
    "    #Transforma a matriz particionada em lista e remove o pixel do centro\n",
    "    lista_de_vizinhos = vizinhos.flatten().tolist()\n",
    "    lista_de_vizinhos.remove(matriz_de_intensidade[linha, coluna])\n",
    "\n",
    "    return lista_de_vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_regras(lista_de_vizinhos, intensidade_pixel_central, estado_pixel_central):\n",
    "    #O objetivo dessa função é aplicar as regras do jogo da vida de Conway no pixel observado e retornar seu estado.\n",
    "    # 1 = vivo, 0 = morto\n",
    "\n",
    "    #Conta o número de vizinhos vivos com a mesma intensidade que o pixel central\n",
    "    vizinhos_iguais = lista_de_vizinhos.count(intensidade_pixel_central)\n",
    "\n",
    "    #Regra 1: A célula viva com dois ou três vizinhos vivos sobrevive\n",
    "    if estado_pixel_central == 1 and (vizinhos_iguais == 2 or vizinhos_iguais == 3):\n",
    "        return 1\n",
    "\n",
    "    #Regra 2: A célula viva com menos de dois vizinhos vivos morre (subpopulação)\n",
    "    elif estado_pixel_central == 1 and vizinhos_iguais < 2:\n",
    "        return 0\n",
    "\n",
    "    #Regra 3: A célula viva com mais de três vizinhos vivos morre (superpopulação)\n",
    "    elif estado_pixel_central == 1 and vizinhos_iguais > 3:\n",
    "        return 0\n",
    "\n",
    "    #Regra 4: A célula morta com exatamente três vizinhos vivos se torna viva (resurreição)\n",
    "    elif estado_pixel_central == 0 and vizinhos_iguais == 3:\n",
    "        return 1\n",
    "\n",
    "    #Pra todos os outros casos, a célula permanece no mesmo estado\n",
    "    else:\n",
    "        return estado_pixel_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percorre_imagem_aplicando_regras(matriz_de_estados, matriz_de_intensidade):\n",
    "    # O objetivo dessa função é percorrer a imagem, chamar a função para obter os vizinhos e aplicar as regras\n",
    "\n",
    "    linhas, colunas = matriz_de_intensidade.shape\n",
    "    for linha in range(linhas):\n",
    "        for coluna in range(colunas):\n",
    "            #Obtem os vizinhos do pixel atual\n",
    "            lista_de_vizinhos = obter_vizinhos(matriz_de_intensidade, linha, coluna)\n",
    "            #Aplica as regras do jogo da vida no pixel atual (atualiza a matriz de estado inicial)\n",
    "            matriz_de_estados[linha, coluna] = aplica_regras(lista_de_vizinhos, matriz_de_intensidade[linha, coluna], matriz_de_estados[linha, coluna])\n",
    "\n",
    "    return matriz_de_estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_histogramas(imagem_cinza):\n",
    "    #O objetivo dessa função é criar as matrizes de intensidade e as de estado inicial para cada imagem\n",
    "    #Após aplicar as regras cria os histogramas\n",
    "\n",
    "    #Transforma a imagem em uma matriz de intensidade\n",
    "    matriz_de_intensidade = np.array(imagem_cinza)\n",
    "\n",
    "    #Cria as matrizes de estados iniciais\n",
    "    matriz_de_estados_phi = np.ones(matriz_de_intensidade.shape, dtype=int) #todos vivos\n",
    "    matriz_de_estados_psi = np.zeros(matriz_de_intensidade.shape, dtype=int) #todos mortos\n",
    "\n",
    "    #Aplica as regras do jogo da vida e atualiza as matrizes de estado inicial\n",
    "    matriz_de_estados_phi = percorre_imagem_aplicando_regras(matriz_de_estados_phi, matriz_de_intensidade)\n",
    "    matriz_de_estados_psi = percorre_imagem_aplicando_regras(matriz_de_estados_psi, matriz_de_intensidade)\n",
    "\n",
    "    #As matrizes são convertidas em listas\n",
    "    #Phi -> estado inicial = vivo\n",
    "    phi_vivos = matriz_de_intensidade.flatten()[matriz_de_estados_phi.flatten() == 1] #se manteram vivos\n",
    "    phi_mortos = matriz_de_intensidade.flatten()[matriz_de_estados_phi.flatten() == 0] #morreram\n",
    "\n",
    "    #Psi -> estado inicial = morto\n",
    "    psi_vivos = matriz_de_intensidade.flatten()[matriz_de_estados_psi.flatten() == 1] #ressuscitaram\n",
    "    psi_mortos = matriz_de_intensidade.flatten()[matriz_de_estados_psi.flatten() == 0] #se manteram mortos\n",
    "\n",
    "    #Cria os histogramas\n",
    "    hist_phi_vivos, _ = np.histogram(phi_vivos, bins=256, range=(0, 256))\n",
    "    hist_phi_mortos, _ = np.histogram(phi_mortos, bins=256, range=(0, 256))\n",
    "    hist_psi_vivos, _ = np.histogram(psi_vivos, bins=256, range=(0, 256))\n",
    "    hist_psi_mortos, _ = np.histogram(psi_mortos, bins=256, range=(0, 256))\n",
    "\n",
    "    return hist_phi_vivos, hist_phi_mortos, hist_psi_vivos, hist_psi_mortos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def gerador_histogramas(dataset_dir, escala):\n",
    "    #Funcao principal: faz a chamada das funções acima e salva os histogramas\n",
    "\n",
    "    images_dir = f\"{dataset_dir}/images\"\n",
    "    histograms_dir = f\"{dataset_dir}/histograms_grayscale\"\n",
    "\n",
    "    # Cria as pastas para salvar os histogramas mantendo o padrão das classes do dataset\n",
    "    os.makedirs(histograms_dir, exist_ok=True)\n",
    "    classes = [conteudo_item for conteudo_item in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, conteudo_item))]\n",
    "    for classe in classes:\n",
    "        dir_pastas = os.path.join(histograms_dir, classe)\n",
    "        os.makedirs(dir_pastas, exist_ok=True)\n",
    "\n",
    "\n",
    "    #Esse loop pega a imagem, gera seus histogramas e salva com base no nome da classe e da imagem\n",
    "    for classe in os.listdir(images_dir):\n",
    "        dir_classe = f\"{images_dir}/{classe}\"\n",
    "        classe = f\"{classe}\"\n",
    "        \n",
    "        lista_arquivos = os.listdir(dir_classe)\n",
    "        num_arquivos = len(lista_arquivos)\n",
    "        \n",
    "        progress_bar = tqdm(total=num_arquivos, desc= classe)\n",
    "        \n",
    "        for imagem in os.listdir(dir_classe):\n",
    "            imagem_path = f\"{images_dir}/{classe}/{imagem}\"\n",
    "\n",
    "            imagem_cinza = cv2.imread(imagem_path, cv2.IMREAD_GRAYSCALE) #Lendo em escala de cinza\n",
    "            imagem_cinza = cv2.resize(imagem_cinza, (escala,escala)) #Padronizando tamanho das imagens\n",
    "            \n",
    "            hist_phi_vivos, hist_phi_mortos, hist_psi_vivos, hist_psi_mortos = gera_histogramas(imagem_cinza)\n",
    "\n",
    "            img_name = imagem.split(\".\")[0]\n",
    "            file_path = os.path.join(f\"{histograms_dir}/{classe}\", f\"{img_name}_phi_vivos.pkl\")\n",
    "            joblib.dump(hist_phi_vivos, file_path)\n",
    "            file_path = os.path.join(f\"{histograms_dir}/{classe}\", f\"{img_name}_phi_mortos.pkl\")\n",
    "            joblib.dump(hist_phi_mortos, file_path)\n",
    "            file_path = os.path.join(f\"{histograms_dir}/{classe}\", f\"{img_name}_psi_vivos.pkl\")\n",
    "            joblib.dump(hist_psi_vivos, file_path)\n",
    "            file_path = os.path.join(f\"{histograms_dir}/{classe}\", f\"{img_name}_psi_mortos.pkl\")\n",
    "            joblib.dump(hist_psi_mortos, file_path)\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        progress_bar.close()\n",
    "\n",
    "    print(\"Progresso concluído\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_hist(imagem_path):\n",
    "    #O objetivo dessa função é carregar os histogramas de determinada imagem\n",
    "\n",
    "    #./data/dataset/images/classe/imagem.jpg\n",
    "    imagem_path = imagem_path.split(\"/\")\n",
    "    dataset, classe, imagem = imagem_path[2], imagem_path[4], imagem_path[5]\n",
    "    imagem = imagem.split(\".\")[0]\n",
    "\n",
    "    histogramas_dir = f\"./data/{dataset}/histograms_grayscale\"\n",
    "\n",
    "    try:\n",
    "        #Buscando os histogramas no diretorio\n",
    "        hist_phi_vivos = joblib.load(f\"{histogramas_dir}/{classe}/{imagem}_phi_vivos.pkl\")\n",
    "        hist_phi_mortos = joblib.load(f\"{histogramas_dir}/{classe}/{imagem}_phi_mortos.pkl\")\n",
    "        hist_psi_vivos = joblib.load(f\"{histogramas_dir}/{classe}/{imagem}_psi_vivos.pkl\")\n",
    "        hist_psi_mortos = joblib.load(f\"{histogramas_dir}/{classe}/{imagem}_psi_mortos.pkl\")\n",
    "\n",
    "        return hist_phi_vivos, hist_phi_mortos, hist_psi_vivos, hist_psi_mortos\n",
    "\n",
    "    except:\n",
    "        print(imagem_path)\n",
    "        print(\"Os histogramas não foram encontrados. Verifique os diretórios e se os histogramas foram criados corretamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_combinacao(imagem_path, combinacao):\n",
    "    # O objetivo dessa funcao é criar combinacoes com os histogramas da imagem\n",
    "\n",
    "    hist_phi_vivos, hist_phi_mortos, hist_psi_vivos, hist_psi_mortos = carrega_hist(imagem_path)\n",
    "    if combinacao == 0:\n",
    "        return hist_phi_vivos\n",
    "    elif combinacao == 1:\n",
    "        return hist_phi_mortos\n",
    "    elif combinacao == 2:\n",
    "        return hist_psi_vivos\n",
    "    elif combinacao == 3:\n",
    "        return hist_psi_mortos\n",
    "    elif combinacao == 4:\n",
    "        return np.concatenate([hist_phi_vivos, hist_phi_mortos]) #histogramas phi\n",
    "    elif combinacao == 5:\n",
    "        return np.concatenate([hist_psi_vivos, hist_psi_mortos]) #histogramas psi\n",
    "    elif combinacao == 6:\n",
    "        return np.concatenate([hist_phi_vivos, hist_psi_vivos]) #histogramas vivos\n",
    "    elif combinacao == 7:\n",
    "        return np.concatenate([hist_phi_mortos, hist_psi_mortos]) #histogramas mortos\n",
    "    elif combinacao == 8:\n",
    "        return np.concatenate([np.concatenate([hist_phi_vivos, hist_phi_mortos]),\n",
    "                               np.concatenate([hist_psi_vivos, hist_psi_mortos])])\n",
    "        #histogramas phi e psi combinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara os dados para treinar o modelo\n",
    "def retorna_dados(images_dir):\n",
    "    histogramas = []\n",
    "    rotulos = []\n",
    "    \n",
    "    for classe in os.listdir(images_dir):\n",
    "        dir_classe = f\"{images_dir}/{classe}\"\n",
    "        print(classe)\n",
    "        for imagem in os.listdir(dir_classe):\n",
    "            imagem_path = f\"{images_dir}/{classe}/{imagem}\"\n",
    "    \n",
    "            #Pode alterar a combinacao\n",
    "            combinacao = retorna_combinacao(imagem_path, 8)\n",
    "    \n",
    "            #Lista dos histogramas\n",
    "            histogramas.append(combinacao)\n",
    "            #lista da classe assossiada ao histograma\n",
    "            rotulos.append(classe)\n",
    "    \n",
    "    print(\"Progresso concluído\")\n",
    "    return histogramas, rotulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Funções p/ RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Geração de histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_vizinhos_rgb(matriz_de_intensidade, linha, coluna):\n",
    "    # O objetivo dessa função é retornar uma lista contendo a intensidade dos 9 vizinhos do pixel observado\n",
    "\n",
    "    #Esse método de partição da matriz foi escolhido para manter a analise dos pixels vizinhos\n",
    "    #dentro dos limites da matriz de intensidade, evitando assim valores negativos ou fora do shape.\n",
    "    vizinhos = matriz_de_intensidade[max(0, linha-1):min(matriz_de_intensidade.shape[0], linha+2),\n",
    "                             max(0, coluna-1):min(matriz_de_intensidade.shape[1], coluna+2)]\n",
    "\n",
    "    #Transforma a matriz particionada em lista e remove o pixel do centro\n",
    "    lista_de_vizinhos = vizinhos.flatten().tolist()\n",
    "    lista_de_vizinhos.remove(matriz_de_intensidade[linha, coluna])\n",
    "\n",
    "    return lista_de_vizinhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplica_regras_rgb(lista_de_vizinhos, intensidade_pixel_central, estado_pixel_central):\n",
    "    #O objetivo dessa função é aplicar as regras do jogo da vida de Conway no pixel observado e retornar seu estado.\n",
    "    # 1 = vivo, 0 = morto\n",
    "\n",
    "    #Conta o número de vizinhos vivos com a mesma intensidade que o pixel central\n",
    "    vizinhos_iguais = lista_de_vizinhos.count(intensidade_pixel_central)\n",
    "\n",
    "    #Regra 1: A célula viva com dois ou três vizinhos vivos sobrevive\n",
    "    if estado_pixel_central == 1 and (vizinhos_iguais == 2 or vizinhos_iguais == 3):\n",
    "        return 1\n",
    "\n",
    "    #Regra 2: A célula viva com menos de dois vizinhos vivos morre (subpopulação)\n",
    "    elif estado_pixel_central == 1 and vizinhos_iguais < 2:\n",
    "        return 0\n",
    "\n",
    "    #Regra 3: A célula viva com mais de três vizinhos vivos morre (superpopulação)\n",
    "    elif estado_pixel_central == 1 and vizinhos_iguais > 3:\n",
    "        return 0\n",
    "\n",
    "    #Regra 4: A célula morta com exatamente três vizinhos vivos se torna viva (resurreição)\n",
    "    elif estado_pixel_central == 0 and vizinhos_iguais == 3:\n",
    "        return 1\n",
    "\n",
    "    #Pra todos os outros casos, a célula permanece no mesmo estado\n",
    "    else:\n",
    "        return estado_pixel_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percorre_imagem_aplicando_regras_rgb(matriz_de_estados, matriz_de_intensidade):\n",
    "    # O objetivo dessa função é percorrer a imagem, chamar a função para obter os vizinhos e aplicar as regras\n",
    "\n",
    "    linhas, colunas = matriz_de_intensidade.shape\n",
    "    for linha in range(linhas):\n",
    "        for coluna in range(colunas):\n",
    "            #Obtem os vizinhos do pixel atual\n",
    "            lista_de_vizinhos = obter_vizinhos_rgb(matriz_de_intensidade, linha, coluna)\n",
    "            #Aplica as regras do jogo da vida no pixel atual (atualiza a matriz de estado inicial)\n",
    "            matriz_de_estados[linha, coluna] = aplica_regras_rgb(lista_de_vizinhos, matriz_de_intensidade[linha, coluna], matriz_de_estados[linha, coluna])\n",
    "\n",
    "    return matriz_de_estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_histogramas_rgb(imagem):\n",
    "    #O objetivo dessa função é criar as matrizes de intensidade e as de estado inicial para cada imagem\n",
    "    #Após aplicar as regras cria os histogramas\n",
    "\n",
    "    #Transforma a imagem em uma matriz de intensidade\n",
    "    matriz_de_intensidade = np.array(imagem)\n",
    "\n",
    "    #Cria as matrizes de estados iniciais\n",
    "    matriz_de_estados_phi = np.ones(matriz_de_intensidade.shape, dtype=int) #todos vivos\n",
    "    matriz_de_estados_psi = np.zeros(matriz_de_intensidade.shape, dtype=int) #todos mortos\n",
    "\n",
    "    #Aplica as regras do jogo da vida e atualiza as matrizes de estado inicial\n",
    "    matriz_de_estados_phi = percorre_imagem_aplicando_regras_rgb(matriz_de_estados_phi, matriz_de_intensidade)\n",
    "    matriz_de_estados_psi = percorre_imagem_aplicando_regras_rgb(matriz_de_estados_psi, matriz_de_intensidade)\n",
    "\n",
    "    #As matrizes são convertidas em listas\n",
    "    #Phi -> estado inicial = vivo\n",
    "    phi_vivos = matriz_de_intensidade.flatten()[matriz_de_estados_phi.flatten() == 1] #se manteram vivos\n",
    "    phi_mortos = matriz_de_intensidade.flatten()[matriz_de_estados_phi.flatten() == 0] #morreram\n",
    "\n",
    "    #Psi -> estado inicial = morto\n",
    "    psi_vivos = matriz_de_intensidade.flatten()[matriz_de_estados_psi.flatten() == 1] #ressuscitaram\n",
    "    psi_mortos = matriz_de_intensidade.flatten()[matriz_de_estados_psi.flatten() == 0] #se manteram mortos\n",
    "\n",
    "    #Cria os histogramas\n",
    "    hist_phi_vivos, _ = np.histogram(phi_vivos, bins=256, range=(0, 256))\n",
    "    hist_phi_mortos, _ = np.histogram(phi_mortos, bins=256, range=(0, 256))\n",
    "    hist_psi_vivos, _ = np.histogram(psi_vivos, bins=256, range=(0, 256))\n",
    "    hist_psi_mortos, _ = np.histogram(psi_mortos, bins=256, range=(0, 256))\n",
    "\n",
    "    return hist_phi_vivos, hist_phi_mortos, hist_psi_vivos, hist_psi_mortos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def gerador_histogramas_RGB(dataset_dir, escala):\n",
    "    images_dir = f\"{dataset_dir}/images\"\n",
    "    histograms_dir = f\"{dataset_dir}/histograms_rgb\"\n",
    "\n",
    "    #Criando diretorios das classes\n",
    "    os.makedirs(histograms_dir, exist_ok=True)\n",
    "    classes = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]\n",
    "    for classe in classes:\n",
    "        os.makedirs(os.path.join(histograms_dir, classe), exist_ok=True)\n",
    "\n",
    "    for classe in classes:\n",
    "        dir_classe = os.path.join(images_dir, classe)\n",
    "\n",
    "        lista_arquivos = os.listdir(dir_classe)\n",
    "        num_arquivos = len(lista_arquivos)\n",
    "        progress_bar = tqdm(total=num_arquivos, desc= classe)\n",
    "        \n",
    "        for imagem in os.listdir(dir_classe):\n",
    "            imagem_path = os.path.join(dir_classe, imagem)\n",
    "            imagem_rgb = cv2.imread(imagem_path, cv2.IMREAD_COLOR) #Lendo a imagem em BGR\n",
    "            imagem_rgb = cv2.resize(imagem_rgb, (escala, escala))\n",
    "\n",
    "            #Gera os histogramas para cada canal da imagem\n",
    "            hist_phi_vivos_b, hist_phi_mortos_b, hist_psi_vivos_b, hist_psi_mortos_b = gera_histogramas_rgb(imagem_rgb[:, :, 0])\n",
    "            hist_phi_vivos_g, hist_phi_mortos_g, hist_psi_vivos_g, hist_psi_mortos_g = gera_histogramas_rgb(imagem_rgb[:, :, 1])\n",
    "            hist_phi_vivos_r, hist_phi_mortos_r, hist_psi_vivos_r, hist_psi_mortos_r = gera_histogramas_rgb(imagem_rgb[:, :, 2])\n",
    "\n",
    "            #Concatena os histogramas dos 3 canais para cada uma das 4 situações após o jogo da vida (vivos->vivos, vivos->mortos, etc.)\n",
    "            hist_phi_vivos = np.concatenate([np.concatenate([hist_phi_vivos_b,hist_phi_vivos_g]),hist_phi_vivos_r])\n",
    "            hist_phi_mortos = np.concatenate([np.concatenate([hist_phi_mortos_b,hist_phi_mortos_g]),hist_phi_mortos_r])\n",
    "            hist_psi_vivos = np.concatenate([np.concatenate([hist_psi_vivos_b,hist_psi_vivos_g]),hist_psi_vivos_r])\n",
    "            hist_psi_mortos = np.concatenate([np.concatenate([hist_psi_mortos_b,hist_psi_mortos_g]),hist_psi_mortos_r])\n",
    "\n",
    "            #salvando os histogramas\n",
    "            index = os.path.splitext(os.path.basename(imagem_path))[0]\n",
    "            file_path = os.path.join(f\"{histograms_dir}/{classe}\", f\"{index}_phi_vivos_bgr.pkl\")\n",
    "            joblib.dump(hist_phi_vivos, file_path)\n",
    "            file_path = os.path.join(f\"{histograms_dir}/{classe}\", f\"{index}_phi_mortos_bgr.pkl\")\n",
    "            joblib.dump(hist_phi_mortos, file_path)\n",
    "            file_path = os.path.join(f\"{histograms_dir}/{classe}\", f\"{index}_psi_vivos_bgr.pkl\")\n",
    "            joblib.dump(hist_psi_vivos, file_path)\n",
    "            file_path = os.path.join(f\"{histograms_dir}/{classe}\", f\"{index}_psi_mortos_bgr.pkl\")\n",
    "            joblib.dump(hist_psi_mortos, file_path)\n",
    "            progress_bar.update(1)\n",
    "\n",
    "                \n",
    "        progress_bar.close()\n",
    "\n",
    "\n",
    "    print(\"Progresso concluído\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_hist_rgb(imagem_path):\n",
    "    #O objetivo dessa função é carregar os histogramas de determinada imagem\n",
    "\n",
    "    #./data/dataset/images/classe/imagem.jpg\n",
    "    imagem_path = imagem_path.split(\"/\")\n",
    "    dataset, classe, imagem = imagem_path[2], imagem_path[4], imagem_path[5]\n",
    "    imagem = imagem.split(\".\")[0]\n",
    "\n",
    "    histogramas_dir = f\"./data/{dataset}/histograms_rgb\"\n",
    "    ##print(imagem_path)\n",
    "    ##print(histogramas_dir)\n",
    "    \n",
    "    try:\n",
    "        hist_phi_vivos = joblib.load(f\"{histogramas_dir}/{classe}/{imagem}_phi_vivos_bgr.pkl\")\n",
    "        hist_phi_mortos = joblib.load(f\"{histogramas_dir}/{classe}/{imagem}_phi_mortos_bgr.pkl\")\n",
    "        hist_psi_vivos = joblib.load(f\"{histogramas_dir}/{classe}/{imagem}_psi_vivos_bgr.pkl\")\n",
    "        hist_psi_mortos = joblib.load(f\"{histogramas_dir}/{classe}/{imagem}_psi_mortos_bgr.pkl\")\n",
    "\n",
    "        return hist_phi_vivos, hist_phi_mortos, hist_psi_vivos, hist_psi_mortos\n",
    "\n",
    "    except:\n",
    "        print(\"Os histogramas não foram encontrados. Verifique os diretórios e se os histogramas foram criados corretamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_combinacao_rgb(imagem_path, combinacao):\n",
    "    # O objetivo dessa funcao é criar combinacoes com os histogramas da imagem\n",
    "\n",
    "    \n",
    "    hist_phi_vivos, hist_phi_mortos, hist_psi_vivos, hist_psi_mortos = carrega_hist_rgb(imagem_path)\n",
    "    \n",
    "    switch = {\n",
    "        0: hist_phi_vivos,\n",
    "        1: hist_phi_mortos,\n",
    "        2: hist_psi_vivos,\n",
    "        3: hist_psi_mortos,\n",
    "        4: np.concatenate([hist_phi_vivos, hist_phi_mortos]),   #histogramas phi\n",
    "        5: np.concatenate([hist_psi_vivos, hist_psi_mortos]),   #histogramas psi\n",
    "        6: np.concatenate([hist_phi_vivos, hist_psi_vivos]),    #histogramas vivos\n",
    "        7: np.concatenate([hist_phi_mortos, hist_psi_mortos]),  #histogramas mortos\n",
    "        8: np.concatenate([np.concatenate([hist_phi_vivos, hist_phi_mortos]),\n",
    "                           np.concatenate([hist_psi_vivos, hist_psi_mortos])])\n",
    "    }\n",
    "    \n",
    "    return switch.get(combinacao, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara os dados para treinar o modelo\n",
    "def retorna_dados_rgb(images_dir): \n",
    "    histogramas_rgb = []\n",
    "    rotulos_rgb = []\n",
    "    \n",
    "    for classe in os.listdir(images_dir):\n",
    "        dir_classe = f\"{images_dir}/{classe}\"\n",
    "        print(classe)\n",
    "        for imagem in os.listdir(dir_classe):\n",
    "            imagem_path = f\"{images_dir}/{classe}/{imagem}\"\n",
    "    \n",
    "            #Pode alterar a combinacao \n",
    "            combinacao = retorna_combinacao_rgb(imagem_path, 8)\n",
    "    \n",
    "            #Lista dos histogramas\n",
    "            histogramas_rgb.append(combinacao)\n",
    "            #lista da classe assossiada ao histograma\n",
    "            rotulos_rgb.append(classe)\n",
    "    \n",
    "    print(\"Progresso concluído\")\n",
    "    return histogramas_rgb, rotulos_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Funções p/ modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(X_train, y_train, X_test, y_test):\n",
    "    # Gaussian Naive Bayes\n",
    "    gnb = GaussianNB()\n",
    "    model1 = gnb.fit(X_train, y_train)\n",
    "    aux = gnb.predict(X_test)\n",
    "    print(classification_report(y_test, aux, zero_division=1))\n",
    "    #print(confusion_matrix(y_test, aux))\n",
    "\n",
    "def logistic_regr(X_train, y_train, X_test, y_test):\n",
    "    # Logistic Regression\n",
    "    logreg = LogisticRegression(max_iter = 1000)\n",
    "    model2 = logreg.fit(X_train, y_train)\n",
    "    aux = logreg.predict(X_test)\n",
    "    print(classification_report(y_test, aux, zero_division=1))\n",
    "    #print(confusion_matrix(y_test, aux))\n",
    "\n",
    "def decision_tree(X_train, y_train, X_test, y_test):\n",
    "    # Decision Tree\n",
    "    dectree = DecisionTreeClassifier()\n",
    "    model3 = dectree.fit(X_train, y_train)\n",
    "    aux = dectree.predict(X_test)\n",
    "    print(classification_report(y_test, aux, zero_division=1))\n",
    "    #print(confusion_matrix(y_test, aux))\n",
    "\n",
    "def knn(X_train, y_train, X_test, y_test):\n",
    "    # K-Nearest Neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "    model4 = knn.fit(X_train, y_train)\n",
    "    aux = knn.predict(X_test)\n",
    "    print(classification_report(y_test, aux, zero_division=1))\n",
    "    #print(confusion_matrix(y_test, aux))\n",
    "\n",
    "def lda(X_train, y_train, X_test, y_test):\n",
    "    # Linear Discriminant Analysis\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    model5 = lda.fit(X_train, y_train)\n",
    "    aux = lda.predict(X_test)\n",
    "    print(classification_report(y_test, aux, zero_division=1))\n",
    "    #print(confusion_matrix(y_test, aux))\n",
    "\n",
    "def svm(X_train, y_train, X_test, y_test):\n",
    "    # Support Vector Machine\n",
    "    svm = SVC()\n",
    "    model6 = svm.fit(X_train, y_train)\n",
    "    aux = svm.predict(X_test)\n",
    "    print(classification_report(y_test, aux, zero_division=1))\n",
    "    #print(confusion_matrix(y_test, aux))\n",
    "\n",
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    # RandomForest\n",
    "    rf = RandomForestClassifier()\n",
    "    model7 = rf.fit(X_train, y_train)\n",
    "    aux = rf.predict(X_test)\n",
    "    print(classification_report(y_test, aux, zero_division=1))\n",
    "    #print(confusion_matrix(y_test, aux))\n",
    "\n",
    "def neural_net(X_train, y_train, X_test, y_test):\n",
    "    # Neural Net\n",
    "    nnet = MLPClassifier(alpha=1)\n",
    "    model8 = nnet.fit(X_train, y_train)\n",
    "    aux = nnet.predict(X_test)\n",
    "    print(classification_report(y_test, aux, zero_division=1))\n",
    "    #print(confusion_matrix(y_test, aux))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset Corel 1k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdJ-9FRqJQm1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Em escala de cinza:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDQfybOh1Ucj",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Gerando histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anqLr2U22_Fy"
   },
   "outputs": [],
   "source": [
    "#gerador_histogramas(dataset_dir, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o3UPHAE4aWR"
   },
   "source": [
    "### Testando modelos de aprendizado de máquina combinando histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3oLo-dp-fzE"
   },
   "outputs": [],
   "source": [
    "histogramas, rotulos = retorna_dados(images_dir)\n",
    "X = np.array(histogramas)\n",
    "y = np.array(rotulos)\n",
    "\n",
    "#Dividindo treino e teste na respectiva proporção (0.8 / 0.2), stratify = y mantém uma proporção entre os dados de teste de cada classe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtKiSkin-pGz"
   },
   "outputs": [],
   "source": [
    "#Utilizando tecnicas de normalizacao\n",
    "# 1 = MinMaxScaler, 2 = StandardScaler, 3 = MaxAbsScaler, 4 = RobustScaler\n",
    "selectedNormalization = 1\n",
    "\n",
    "if selectedNormalization == 1:\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "if selectedNormalization == 2:\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "if selectedNormalization == 3:\n",
    "    scaler = preprocessing.MaxAbsScaler()\n",
    "if selectedNormalization == 4:\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# Escalando os dados de treinamento\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Escalando os dados de teste com os dados de treinamento, visto que os dados de teste podem ser apenas 1 amostra\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3NP2RnS_x3D",
    "outputId": "a1a2ad1b-07a8-4de8-e360-e3e2f4b22604"
   },
   "outputs": [],
   "source": [
    "gaussian(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLJhHrGs_0ab",
    "outputId": "6231716e-4054-4ad8-e171-5c7a1aac8240"
   },
   "outputs": [],
   "source": [
    "logistic_regr(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSUuAjKT_1ez",
    "outputId": "4486eb7a-e510-4c0c-b29c-35edb47a8291"
   },
   "outputs": [],
   "source": [
    "decision_tree(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUHi1qN4_25j",
    "outputId": "17eec87e-db4b-4a29-c927-2dde5a07812e"
   },
   "outputs": [],
   "source": [
    "knn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BvzliFey_4CT",
    "outputId": "1c52c97a-2eb0-4560-dc16-a55864279a83"
   },
   "outputs": [],
   "source": [
    "lda(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2OCnj6a_5l0",
    "outputId": "0d2d4a86-b796-4542-9e90-0661c984bba1"
   },
   "outputs": [],
   "source": [
    "svm(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfmpE0K8_6iy",
    "outputId": "4fb8783c-936a-451d-8a95-ae34d31478c9"
   },
   "outputs": [],
   "source": [
    "random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rF_-ULJF_7ZL",
    "outputId": "08c78e30-1c53-4693-957e-609ff1cb1294"
   },
   "outputs": [],
   "source": [
    "neural_net(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Em RGB:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Gerando histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerador_histogramas_RGB(dataset_dir, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando modelos de aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogramas_rgb, rotulos_rgb = retorna_dados_rgb(images_dir)\n",
    "X = np.array(histogramas_rgb)\n",
    "y = np.array(rotulos_rgb)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando tecnicas de normalizacao\n",
    "# 1 = MinMaxScaler, 2 = StandardScaler, 3 = MaxAbsScaler, 4 = RobustScaler\n",
    "selectedNormalization = 1\n",
    "\n",
    "if selectedNormalization == 1:\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "if selectedNormalization == 2:\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "if selectedNormalization == 3:\n",
    "    scaler = preprocessing.MaxAbsScaler()\n",
    "if selectedNormalization == 4:\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# Escalando os dados de treinamento\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Escalando os dados de teste com os dados de treinamento, visto que os dados de teste podem ser apenas 1 amostra\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQy0zeioJZis",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset_1 Caltech256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVmW9D-CJdwd"
   },
   "source": [
    "## Em RBG:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzGzBaQfJja-"
   },
   "source": [
    "### Gerando histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H53ODYudNj40",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gerador_histogramas_RGB(dataset_1_dir, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7LdASJ9Jnt-"
   },
   "source": [
    "### Testando modelos de aprendizado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001.ak47\n",
      "002.american-flag\n",
      "003.backpack\n",
      "004.baseball-bat\n",
      "005.baseball-glove\n",
      "006.basketball-hoop\n",
      "007.bat\n",
      "008.bathtub\n",
      "009.bear\n",
      "010.beer-mug\n",
      "011.billiards\n",
      "012.binoculars\n",
      "013.birdbath\n",
      "014.blimp\n",
      "015.bonsai-101\n",
      "016.boom-box\n",
      "017.bowling-ball\n",
      "018.bowling-pin\n",
      "019.boxing-glove\n",
      "020.brain-101\n",
      "021.breadmaker\n",
      "022.buddha-101\n",
      "023.bulldozer\n",
      "024.butterfly\n",
      "025.cactus\n",
      "026.cake\n",
      "027.calculator\n",
      "028.camel\n",
      "029.cannon\n",
      "030.canoe\n",
      "031.car-tire\n",
      "032.cartman\n",
      "033.cd\n",
      "034.centipede\n",
      "035.cereal-box\n",
      "036.chandelier-101\n",
      "037.chess-board\n",
      "038.chimp\n",
      "039.chopsticks\n",
      "040.cockroach\n",
      "041.coffee-mug\n",
      "042.coffin\n",
      "043.coin\n",
      "044.comet\n",
      "045.computer-keyboard\n",
      "046.computer-monitor\n",
      "047.computer-mouse\n",
      "048.conch\n",
      "049.cormorant\n",
      "050.covered-wagon\n",
      "051.cowboy-hat\n",
      "052.crab-101\n",
      "053.desk-globe\n",
      "054.diamond-ring\n",
      "055.dice\n",
      "056.dog\n",
      "057.dolphin-101\n",
      "058.doorknob\n",
      "059.drinking-straw\n",
      "060.duck\n",
      "061.dumb-bell\n",
      "062.eiffel-tower\n",
      "063.electric-guitar-101\n",
      "064.elephant-101\n",
      "065.elk\n",
      "066.ewer-101\n",
      "067.eyeglasses\n",
      "068.fern\n",
      "069.fighter-jet\n",
      "070.fire-extinguisher\n",
      "071.fire-hydrant\n",
      "072.fire-truck\n",
      "073.fireworks\n",
      "074.flashlight\n",
      "075.floppy-disk\n",
      "076.football-helmet\n",
      "077.french-horn\n",
      "078.fried-egg\n",
      "079.frisbee\n",
      "080.frog\n",
      "081.frying-pan\n",
      "082.galaxy\n",
      "083.gas-pump\n",
      "084.giraffe\n",
      "085.goat\n",
      "086.golden-gate-bridge\n",
      "087.goldfish\n",
      "088.golf-ball\n",
      "089.goose\n",
      "090.gorilla\n",
      "091.grand-piano-101\n",
      "092.grapes\n",
      "093.grasshopper\n",
      "094.guitar-pick\n",
      "095.hamburger\n",
      "096.hammock\n",
      "097.harmonica\n",
      "098.harp\n",
      "099.harpsichord\n",
      "100.hawksbill-101\n",
      "101.head-phones\n",
      "102.helicopter-101\n",
      "103.hibiscus\n",
      "104.homer-simpson\n",
      "105.horse\n",
      "106.horseshoe-crab\n",
      "107.hot-air-balloon\n",
      "108.hot-dog\n",
      "109.hot-tub\n",
      "110.hourglass\n",
      "111.house-fly\n",
      "112.human-skeleton\n",
      "113.hummingbird\n",
      "114.ibis-101\n",
      "115.ice-cream-cone\n",
      "116.iguana\n",
      "117.ipod\n",
      "118.iris\n",
      "119.jesus-christ\n",
      "120.joy-stick\n",
      "121.kangaroo-101\n",
      "122.kayak\n",
      "123.ketch-101\n",
      "124.killer-whale\n",
      "125.knife\n",
      "126.ladder\n",
      "127.laptop-101\n",
      "128.lathe\n",
      "129.leopards-101\n",
      "130.license-plate\n",
      "131.lightbulb\n",
      "132.light-house\n",
      "133.lightning\n",
      "134.llama-101\n",
      "135.mailbox\n",
      "136.mandolin\n",
      "137.mars\n",
      "138.mattress\n",
      "139.megaphone\n",
      "140.menorah-101\n",
      "141.microscope\n",
      "142.microwave\n",
      "143.minaret\n",
      "144.minotaur\n",
      "145.motorbikes-101\n",
      "146.mountain-bike\n",
      "147.mushroom\n",
      "148.mussels\n",
      "149.necktie\n",
      "150.octopus\n",
      "151.ostrich\n",
      "152.owl\n",
      "153.palm-pilot\n",
      "154.palm-tree\n",
      "155.paperclip\n",
      "156.paper-shredder\n",
      "157.pci-card\n",
      "158.penguin\n",
      "159.people\n",
      "160.pez-dispenser\n",
      "161.photocopier\n",
      "162.picnic-table\n",
      "163.playing-card\n",
      "164.porcupine\n",
      "165.pram\n",
      "166.praying-mantis\n",
      "167.pyramid\n",
      "168.raccoon\n",
      "169.radio-telescope\n",
      "170.rainbow\n",
      "171.refrigerator\n",
      "172.revolver-101\n",
      "173.rifle\n",
      "174.rotary-phone\n",
      "175.roulette-wheel\n",
      "176.saddle\n",
      "177.saturn\n",
      "178.school-bus\n",
      "179.scorpion-101\n",
      "180.screwdriver\n",
      "181.segway\n",
      "182.self-propelled-lawn-mower\n",
      "183.sextant\n",
      "184.sheet-music\n",
      "185.skateboard\n",
      "186.skunk\n",
      "187.skyscraper\n",
      "188.smokestack\n",
      "189.snail\n",
      "190.snake\n",
      "191.sneaker\n",
      "192.snowmobile\n",
      "193.soccer-ball\n",
      "194.socks\n",
      "195.soda-can\n",
      "196.spaghetti\n",
      "197.speed-boat\n",
      "198.spider\n",
      "199.spoon\n",
      "200.stained-glass\n",
      "201.starfish-101\n",
      "202.steering-wheel\n",
      "203.stirrups\n",
      "204.sunflower-101\n",
      "205.superman\n",
      "206.sushi\n",
      "207.swan\n",
      "208.swiss-army-knife\n",
      "209.sword\n",
      "210.syringe\n",
      "211.tambourine\n",
      "212.teapot\n",
      "213.teddy-bear\n",
      "214.teepee\n",
      "215.telephone-box\n",
      "216.tennis-ball\n",
      "217.tennis-court\n",
      "218.tennis-racket\n",
      "219.theodolite\n",
      "220.toaster\n",
      "221.tomato\n",
      "222.tombstone\n",
      "223.top-hat\n",
      "224.touring-bike\n",
      "225.tower-pisa\n",
      "226.traffic-light\n",
      "227.treadmill\n",
      "228.triceratops\n",
      "229.tricycle\n",
      "230.trilobite-101\n",
      "231.tripod\n",
      "232.t-shirt\n",
      "233.tuning-fork\n",
      "234.tweezer\n",
      "235.umbrella-101\n",
      "236.unicorn\n",
      "237.vcr\n",
      "238.video-projector\n",
      "239.washing-machine\n",
      "240.watch-101\n",
      "241.waterfall\n",
      "242.watermelon\n",
      "243.welding-mask\n",
      "244.wheelbarrow\n",
      "245.windmill\n",
      "246.wine-bottle\n",
      "247.xylophone\n",
      "248.yarmulke\n",
      "249.yo-yo\n",
      "250.zebra\n",
      "251.airplanes-101\n",
      "252.car-side-101\n",
      "253.faces-easy-101\n",
      "254.greyhound\n",
      "255.tennis-shoes\n",
      "256.toad\n",
      "257.clutter\n",
      "Progresso concluído\n"
     ]
    }
   ],
   "source": [
    "histogramas_rgb, rotulos_rgb = retorna_dados_rgb(images_1_dir)\n",
    "X = np.array(histogramas_rgb)\n",
    "y = np.array(rotulos_rgb)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando tecnicas de normalizacao\n",
    "# 1 = MinMaxScaler, 2 = StandardScaler, 3 = MaxAbsScaler, 4 = RobustScaler\n",
    "selectedNormalization = 1\n",
    "\n",
    "if selectedNormalization == 1:\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "if selectedNormalization == 2:\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "if selectedNormalization == 3:\n",
    "    scaler = preprocessing.MaxAbsScaler()\n",
    "if selectedNormalization == 4:\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# Escalando os dados de treinamento\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Escalando os dados de teste com os dados de treinamento, visto que os dados de teste podem ser apenas 1 amostra\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               precision    recall  f1-score   support\n",
      "\n",
      "                     001.ak47       0.00      0.00      0.00        20\n",
      "            002.american-flag       0.00      0.00      0.00        19\n",
      "                 003.backpack       0.09      0.23      0.13        30\n",
      "             004.baseball-bat       0.00      0.00      0.00        25\n",
      "           005.baseball-glove       0.06      0.07      0.06        30\n",
      "          006.basketball-hoop       0.00      0.00      0.00        18\n",
      "                      007.bat       0.00      0.00      0.00        21\n",
      "                  008.bathtub       0.00      0.00      0.00        47\n",
      "                     009.bear       0.00      0.00      0.00        20\n",
      "                 010.beer-mug       0.00      0.00      0.00        19\n",
      "                011.billiards       0.00      0.00      0.00        56\n",
      "               012.binoculars       0.09      0.07      0.08        43\n",
      "                 013.birdbath       0.00      0.00      0.00        20\n",
      "                    014.blimp       0.00      0.00      0.00        17\n",
      "               015.bonsai-101       0.00      0.00      0.00        24\n",
      "                 016.boom-box       0.03      0.06      0.04        18\n",
      "             017.bowling-ball       0.00      0.00      0.00        21\n",
      "              018.bowling-pin       0.00      0.00      0.00        20\n",
      "             019.boxing-glove       0.00      0.00      0.00        25\n",
      "                020.brain-101       0.03      0.24      0.05        17\n",
      "               021.breadmaker       0.06      0.39      0.10        28\n",
      "               022.buddha-101       0.00      0.00      0.00        19\n",
      "                023.bulldozer       0.00      0.00      0.00        22\n",
      "                024.butterfly       0.00      0.00      0.00        22\n",
      "                   025.cactus       0.00      0.00      0.00        23\n",
      "                     026.cake       0.00      0.00      0.00        21\n",
      "               027.calculator       0.00      0.00      0.00        20\n",
      "                    028.camel       0.00      0.00      0.00        22\n",
      "                   029.cannon       0.20      0.05      0.08        21\n",
      "                    030.canoe       0.00      0.00      0.00        21\n",
      "                 031.car-tire       0.00      0.00      0.00        18\n",
      "                  032.cartman       1.00      0.05      0.10        20\n",
      "                       033.cd       0.00      0.00      0.00        20\n",
      "                034.centipede       0.00      0.00      0.00        20\n",
      "               035.cereal-box       0.00      0.00      0.00        17\n",
      "           036.chandelier-101       0.00      0.00      0.00        21\n",
      "              037.chess-board       0.00      0.00      0.00        24\n",
      "                    038.chimp       0.00      0.00      0.00        22\n",
      "               039.chopsticks       0.00      0.00      0.00        17\n",
      "                040.cockroach       0.00      0.00      0.00        25\n",
      "               041.coffee-mug       0.00      0.00      0.00        17\n",
      "                   042.coffin       0.00      0.00      0.00        17\n",
      "                     043.coin       0.00      0.00      0.00        25\n",
      "                    044.comet       0.04      0.17      0.06        24\n",
      "        045.computer-keyboard       0.00      0.00      0.00        17\n",
      "         046.computer-monitor       0.00      0.00      0.00        27\n",
      "           047.computer-mouse       0.00      0.00      0.00        19\n",
      "                    048.conch       0.00      0.00      0.00        21\n",
      "                049.cormorant       0.00      0.00      0.00        21\n",
      "            050.covered-wagon       0.00      0.00      0.00        19\n",
      "               051.cowboy-hat       0.00      0.00      0.00        23\n",
      "                 052.crab-101       0.00      0.00      0.00        17\n",
      "               053.desk-globe       0.03      0.06      0.04        16\n",
      "             054.diamond-ring       0.00      0.00      0.00        24\n",
      "                     055.dice       0.00      0.00      0.00        20\n",
      "                      056.dog       0.00      0.00      0.00        20\n",
      "              057.dolphin-101       0.08      0.10      0.09        21\n",
      "                 058.doorknob       0.00      0.00      0.00        19\n",
      "           059.drinking-straw       0.20      0.06      0.09        17\n",
      "                     060.duck       0.00      0.00      0.00        17\n",
      "                061.dumb-bell       0.00      0.00      0.00        20\n",
      "             062.eiffel-tower       0.00      0.00      0.00        17\n",
      "      063.electric-guitar-101       0.00      0.00      0.00        24\n",
      "             064.elephant-101       0.00      0.00      0.00        26\n",
      "                      065.elk       0.00      0.00      0.00        20\n",
      "                 066.ewer-101       0.00      0.00      0.00        17\n",
      "               067.eyeglasses       0.00      0.00      0.00        17\n",
      "                     068.fern       0.00      0.00      0.00        22\n",
      "              069.fighter-jet       0.00      0.00      0.00        20\n",
      "        070.fire-extinguisher       0.33      0.06      0.10        17\n",
      "             071.fire-hydrant       0.00      0.00      0.00        20\n",
      "               072.fire-truck       0.00      0.00      0.00        24\n",
      "                073.fireworks       0.05      0.45      0.09        20\n",
      "               074.flashlight       0.00      0.00      0.00        23\n",
      "              075.floppy-disk       0.00      0.00      0.00        17\n",
      "          076.football-helmet       0.00      0.00      0.00        17\n",
      "              077.french-horn       0.00      0.00      0.00        18\n",
      "                078.fried-egg       0.00      0.00      0.00        18\n",
      "                  079.frisbee       0.00      0.00      0.00        20\n",
      "                     080.frog       0.00      0.00      0.00        23\n",
      "               081.frying-pan       0.00      0.00      0.00        19\n",
      "                   082.galaxy       0.06      0.62      0.11        16\n",
      "                 083.gas-pump       0.00      0.00      0.00        19\n",
      "                  084.giraffe       0.00      0.00      0.00        17\n",
      "                     085.goat       0.00      0.00      0.00        22\n",
      "       086.golden-gate-bridge       0.08      0.06      0.07        16\n",
      "                 087.goldfish       0.00      0.00      0.00        19\n",
      "                088.golf-ball       0.00      0.00      0.00        20\n",
      "                    089.goose       0.00      0.00      0.00        22\n",
      "                  090.gorilla       0.04      0.19      0.07        43\n",
      "          091.grand-piano-101       0.00      0.00      0.00        19\n",
      "                   092.grapes       0.00      0.00      0.00        40\n",
      "              093.grasshopper       0.00      0.00      0.00        22\n",
      "              094.guitar-pick       0.07      0.05      0.06        21\n",
      "                095.hamburger       0.00      0.00      0.00        17\n",
      "                  096.hammock       0.00      0.00      0.00        57\n",
      "                097.harmonica       0.00      0.00      0.00        18\n",
      "                     098.harp       0.00      0.00      0.00        20\n",
      "              099.harpsichord       0.00      0.00      0.00        16\n",
      "            100.hawksbill-101       0.09      0.16      0.12        19\n",
      "              101.head-phones       0.00      0.00      0.00        28\n",
      "           102.helicopter-101       0.04      0.06      0.05        18\n",
      "                 103.hibiscus       0.03      0.27      0.06        22\n",
      "            104.homer-simpson       0.00      0.00      0.00        19\n",
      "                    105.horse       0.00      0.00      0.00        54\n",
      "           106.horseshoe-crab       0.00      0.00      0.00        17\n",
      "          107.hot-air-balloon       0.00      0.00      0.00        18\n",
      "                  108.hot-dog       0.00      0.00      0.00        17\n",
      "                  109.hot-tub       0.02      0.03      0.02        31\n",
      "                110.hourglass       0.00      0.00      0.00        17\n",
      "                111.house-fly       0.00      0.00      0.00        17\n",
      "           112.human-skeleton       0.00      0.00      0.00        17\n",
      "              113.hummingbird       0.00      0.00      0.00        23\n",
      "                 114.ibis-101       0.00      0.00      0.00        24\n",
      "           115.ice-cream-cone       0.00      0.00      0.00        18\n",
      "                   116.iguana       0.00      0.00      0.00        21\n",
      "                     117.ipod       0.00      0.00      0.00        24\n",
      "                     118.iris       0.00      0.00      0.00        22\n",
      "             119.jesus-christ       0.00      0.00      0.00        17\n",
      "                120.joy-stick       0.33      0.04      0.07        26\n",
      "             121.kangaroo-101       0.02      0.06      0.03        16\n",
      "                    122.kayak       0.00      0.00      0.00        21\n",
      "                123.ketch-101       0.00      0.00      0.00        22\n",
      "             124.killer-whale       0.29      0.11      0.16        18\n",
      "                    125.knife       0.00      0.00      0.00        20\n",
      "                   126.ladder       0.00      0.00      0.00        49\n",
      "               127.laptop-101       0.00      0.00      0.00        26\n",
      "                    128.lathe       0.00      0.00      0.00        21\n",
      "             129.leopards-101       0.30      0.53      0.38        38\n",
      "            130.license-plate       0.00      0.00      0.00        18\n",
      "                131.lightbulb       0.33      0.11      0.17        18\n",
      "              132.light-house       0.00      0.00      0.00        38\n",
      "                133.lightning       0.09      0.26      0.13        27\n",
      "                134.llama-101       0.00      0.00      0.00        24\n",
      "                  135.mailbox       0.00      0.00      0.00        19\n",
      "                 136.mandolin       0.00      0.00      0.00        19\n",
      "                     137.mars       0.24      0.48      0.32        31\n",
      "                 138.mattress       0.20      0.03      0.05        38\n",
      "                139.megaphone       0.06      0.06      0.06        17\n",
      "              140.menorah-101       0.00      0.00      0.00        18\n",
      "               141.microscope       0.00      0.00      0.00        23\n",
      "                142.microwave       0.00      0.00      0.00        21\n",
      "                  143.minaret       0.00      0.00      0.00        26\n",
      "                 144.minotaur       0.00      0.00      0.00        16\n",
      "           145.motorbikes-101       0.09      0.06      0.07       160\n",
      "            146.mountain-bike       0.00      0.00      0.00        16\n",
      "                 147.mushroom       0.00      0.00      0.00        41\n",
      "                  148.mussels       0.14      0.03      0.05        35\n",
      "                  149.necktie       0.00      0.00      0.00        21\n",
      "                  150.octopus       0.00      0.00      0.00        22\n",
      "                  151.ostrich       0.00      0.00      0.00        22\n",
      "                      152.owl       0.00      0.00      0.00        24\n",
      "               153.palm-pilot       0.00      0.00      0.00        19\n",
      "                154.palm-tree       0.06      0.10      0.07        21\n",
      "                155.paperclip       0.00      0.00      0.00        18\n",
      "           156.paper-shredder       0.20      0.11      0.14        19\n",
      "                 157.pci-card       0.00      0.00      0.00        21\n",
      "                  158.penguin       0.00      0.00      0.00        30\n",
      "                   159.people       0.00      0.00      0.00        42\n",
      "            160.pez-dispenser       0.00      0.00      0.00        17\n",
      "              161.photocopier       0.03      0.10      0.05        21\n",
      "             162.picnic-table       0.00      0.00      0.00        18\n",
      "             163.playing-card       0.00      0.00      0.00        18\n",
      "                164.porcupine       0.00      0.00      0.00        20\n",
      "                     165.pram       0.00      0.00      0.00        18\n",
      "           166.praying-mantis       0.00      0.00      0.00        18\n",
      "                  167.pyramid       0.00      0.00      0.00        17\n",
      "                  168.raccoon       0.00      0.00      0.00        28\n",
      "          169.radio-telescope       0.00      0.00      0.00        18\n",
      "                  170.rainbow       0.02      0.10      0.04        20\n",
      "             171.refrigerator       0.00      0.00      0.00        17\n",
      "             172.revolver-101       0.00      0.00      0.00        20\n",
      "                    173.rifle       0.00      0.00      0.00        21\n",
      "             174.rotary-phone       0.00      0.00      0.00        17\n",
      "           175.roulette-wheel       0.02      0.06      0.02        17\n",
      "                   176.saddle       0.00      0.00      0.00        22\n",
      "                   177.saturn       0.29      0.32      0.30        19\n",
      "               178.school-bus       0.00      0.00      0.00        20\n",
      "             179.scorpion-101       0.00      0.00      0.00        16\n",
      "              180.screwdriver       0.00      0.00      0.00        20\n",
      "                   181.segway       0.10      0.05      0.07        20\n",
      "182.self-propelled-lawn-mower       0.02      0.54      0.04        24\n",
      "                  183.sextant       0.00      0.00      0.00        20\n",
      "              184.sheet-music       0.02      0.18      0.03        17\n",
      "               185.skateboard       0.00      0.00      0.00        21\n",
      "                    186.skunk       0.08      0.06      0.07        16\n",
      "               187.skyscraper       0.00      0.00      0.00        19\n",
      "               188.smokestack       0.00      0.00      0.00        18\n",
      "                    189.snail       0.00      0.00      0.00        24\n",
      "                    190.snake       0.00      0.00      0.00        22\n",
      "                  191.sneaker       0.00      0.00      0.00        22\n",
      "               192.snowmobile       0.06      0.09      0.07        22\n",
      "              193.soccer-ball       0.00      0.00      0.00        35\n",
      "                    194.socks       0.00      0.00      0.00        22\n",
      "                 195.soda-can       0.00      0.00      0.00        17\n",
      "                196.spaghetti       0.00      0.00      0.00        21\n",
      "               197.speed-boat       0.00      0.00      0.00        20\n",
      "                   198.spider       0.00      0.00      0.00        22\n",
      "                    199.spoon       0.00      0.00      0.00        21\n",
      "            200.stained-glass       0.00      0.00      0.00        20\n",
      "             201.starfish-101       0.00      0.00      0.00        16\n",
      "           202.steering-wheel       0.00      0.00      0.00        19\n",
      "                 203.stirrups       0.00      0.00      0.00        18\n",
      "            204.sunflower-101       0.00      0.00      0.00        16\n",
      "                 205.superman       0.50      0.06      0.11        17\n",
      "                    206.sushi       0.03      0.05      0.04        20\n",
      "                     207.swan       0.05      0.04      0.04        23\n",
      "         208.swiss-army-knife       0.00      0.00      0.00        22\n",
      "                    209.sword       0.00      0.00      0.00        20\n",
      "                  210.syringe       0.00      0.00      0.00        22\n",
      "               211.tambourine       0.00      0.00      0.00        19\n",
      "                   212.teapot       0.00      0.00      0.00        27\n",
      "               213.teddy-bear       0.00      0.00      0.00        20\n",
      "                   214.teepee       0.00      0.00      0.00        28\n",
      "            215.telephone-box       0.08      0.06      0.07        17\n",
      "              216.tennis-ball       0.25      0.05      0.08        20\n",
      "             217.tennis-court       0.00      0.00      0.00        21\n",
      "            218.tennis-racket       0.00      0.00      0.00        16\n",
      "               219.theodolite       0.00      0.00      0.00        17\n",
      "                  220.toaster       0.00      0.00      0.00        19\n",
      "                   221.tomato       0.14      0.05      0.07        21\n",
      "                222.tombstone       0.00      0.00      0.00        18\n",
      "                  223.top-hat       0.00      0.00      0.00        16\n",
      "             224.touring-bike       0.05      0.05      0.05        22\n",
      "               225.tower-pisa       0.09      0.06      0.07        18\n",
      "            226.traffic-light       0.00      0.00      0.00        20\n",
      "                227.treadmill       0.00      0.00      0.00        29\n",
      "              228.triceratops       0.00      0.00      0.00        19\n",
      "                 229.tricycle       0.00      0.00      0.00        19\n",
      "            230.trilobite-101       0.02      0.32      0.04        19\n",
      "                   231.tripod       0.00      0.00      0.00        22\n",
      "                  232.t-shirt       0.07      0.01      0.02        72\n",
      "              233.tuning-fork       0.00      0.00      0.00        20\n",
      "                  234.tweezer       0.00      0.00      0.00        24\n",
      "             235.umbrella-101       0.00      0.00      0.00        23\n",
      "                  236.unicorn       0.00      0.00      0.00        19\n",
      "                      237.vcr       0.00      0.00      0.00        18\n",
      "          238.video-projector       0.00      0.00      0.00        19\n",
      "          239.washing-machine       0.00      0.00      0.00        17\n",
      "                240.watch-101       0.00      0.00      0.00        40\n",
      "                241.waterfall       0.02      0.21      0.04        19\n",
      "               242.watermelon       0.00      0.00      0.00        19\n",
      "             243.welding-mask       0.10      0.06      0.07        18\n",
      "              244.wheelbarrow       0.00      0.00      0.00        18\n",
      "                 245.windmill       0.00      0.00      0.00        18\n",
      "              246.wine-bottle       0.00      0.00      0.00        20\n",
      "                247.xylophone       0.00      0.00      0.00        18\n",
      "                 248.yarmulke       0.00      0.00      0.00        17\n",
      "                    249.yo-yo       0.00      0.00      0.00        20\n",
      "                    250.zebra       0.04      0.11      0.06        19\n",
      "            251.airplanes-101       0.35      0.40      0.37       160\n",
      "             252.car-side-101       0.08      0.70      0.14        23\n",
      "           253.faces-easy-101       0.23      0.29      0.26        87\n",
      "                254.greyhound       0.67      0.11      0.18        19\n",
      "             255.tennis-shoes       0.06      0.10      0.08        21\n",
      "                     256.toad       0.02      0.05      0.02        22\n",
      "                  257.clutter       0.19      0.04      0.06       166\n",
      "\n",
      "                     accuracy                           0.05      6122\n",
      "                    macro avg       0.03      0.04      0.02      6122\n",
      "                 weighted avg       0.05      0.05      0.04      6122\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastiao\\Desktop\\Projetos\\projeto-ic-automatocelular\\projeto-ic-automatocelular\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sebastiao\\Desktop\\Projetos\\projeto-ic-automatocelular\\projeto-ic-automatocelular\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sebastiao\\Desktop\\Projetos\\projeto-ic-automatocelular\\projeto-ic-automatocelular\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gaussian(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Em escala de cinza:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Gerando histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerador_histogramas(dataset_1_dir, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testando modelos de aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histogramas, rotulos = retorna_dados(images_1_dir)\n",
    "X = np.array(histogramas)\n",
    "y = np.array(rotulos)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando tecnicas de normalizacao\n",
    "# 1 = MinMaxScaler, 2 = StandardScaler, 3 = MaxAbsScaler, 4 = RobustScaler\n",
    "selectedNormalization = 1\n",
    "\n",
    "if selectedNormalization == 1:\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "if selectedNormalization == 2:\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "if selectedNormalization == 3:\n",
    "    scaler = preprocessing.MaxAbsScaler()\n",
    "if selectedNormalization == 4:\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# Escalando os dados de treinamento\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Escalando os dados de teste com os dados de treinamento, visto que os dados de teste podem ser apenas 1 amostra\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_regr(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision_tree(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neural_net(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset_2 CIFAR 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Em escala de cinza:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Gerando histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gerador_histogramas(dataset_2_dir, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testando modelos de aprendizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histogramas, rotulos = retorna_dados(images_2_dir)\n",
    "X = np.array(histogramas)\n",
    "y = np.array(rotulos)\n",
    "\n",
    "#Dividindo treino e teste na respectiva proporção (0.8 / 0.2), stratify = y mantém uma proporção entre os dados de teste de cada classe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando tecnicas de normalizacao\n",
    "# 1 = MinMaxScaler, 2 = StandardScaler, 3 = MaxAbsScaler, 4 = RobustScaler\n",
    "selectedNormalization = 1\n",
    "\n",
    "if selectedNormalization == 1:\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "if selectedNormalization == 2:\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "if selectedNormalization == 3:\n",
    "    scaler = preprocessing.MaxAbsScaler()\n",
    "if selectedNormalization == 4:\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# Escalando os dados de treinamento\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Escalando os dados de teste com os dados de treinamento, visto que os dados de teste podem ser apenas 1 amostra\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gaussian(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_regr(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision_tree(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neural_net(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Em RGB:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Gerando histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerador_histogramas_RGB(dataset_2_dir, 32) #escala em 32 pq o dataset vem em 32x32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histogramas_rgb, rotulos_rgb = retorna_dados_rgb(images_2_dir)\n",
    "X = np.array(histogramas_rgb)\n",
    "y = np.array(rotulos_rgb)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando tecnicas de normalizacao\n",
    "# 1 = MinMaxScaler, 2 = StandardScaler, 3 = MaxAbsScaler, 4 = RobustScaler\n",
    "selectedNormalization = 1\n",
    "\n",
    "if selectedNormalization == 1:\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "if selectedNormalization == 2:\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "if selectedNormalization == 3:\n",
    "    scaler = preprocessing.MaxAbsScaler()\n",
    "if selectedNormalization == 4:\n",
    "    scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# Escalando os dados de treinamento\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Escalando os dados de teste com os dados de treinamento, visto que os dados de teste podem ser apenas 1 amostra\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gaussian(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic_regr(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision_tree(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_forest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neural_net(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "fDQfybOh1Ucj",
    "3o3UPHAE4aWR"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
